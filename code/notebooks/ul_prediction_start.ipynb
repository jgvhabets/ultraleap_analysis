{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can be used to load raw ultraleap data, \n",
    "save cleaned dataframes for each block, \n",
    "and generate dataframes of distances for further feature extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import public packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from itertools import compress\n",
    "\n",
    "\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "import math\n",
    "import statistics as stat\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_path_in_notebook():\n",
    "    \"\"\"\n",
    "    Finds path of repo from Notebook.\n",
    "    Start running this once to correctly find\n",
    "    other modules/functions\n",
    "    \"\"\"\n",
    "    path = os.getcwd()\n",
    "    repo_name = 'ultraleap_analysis'\n",
    "\n",
    "    while path[-len(repo_name):] != 'ultraleap_analysis':\n",
    "\n",
    "        path = os.path.dirname(path)\n",
    "\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = get_repo_path_in_notebook()\n",
    "code_path = os.path.join(repo_path, 'code')\n",
    "os.chdir(code_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import own functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_data.import_and_convert_data as import_dat\n",
    "import import_data.find_paths as find_paths\n",
    "import import_data.preprocessing_meta_info as meta_info\n",
    "import sig_processing.segment_tasks as seg_tasks\n",
    "import movement_calc.helpfunctions as hp\n",
    "import feature_extraction.get_features as get_feat\n",
    "import feature_extraction.get_files as get_files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading Features (X) and scores (y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load features from csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df_path = os.path.join(repo_path, 'data', 'features', 'dataframes', 'patientdata')\n",
    "\n",
    "X_df = pd.read_csv(os.path.join(feat_df_path, 'ft_block_features.csv'), index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load scores / labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_for_feat_df(ft_df):\n",
    "\n",
    "    y = []  # list to store labels\n",
    "\n",
    "    ids = X_df['filename']\n",
    "    if ids[0].startswith('feat'): ids = [x[5:-5] for x in ids]\n",
    "    else: ids = [x[:-5] for x in ids]\n",
    "\n",
    "    ids = [x.split('_') for x in ids]\n",
    "\n",
    "    for id_list in ids:\n",
    "        block, sub, cond, cam, task, side = id_list\n",
    "        value = get_files.get_scores(sub, cond, cam, task, side, block)\n",
    "        y.append(value)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = get_labels_for_feat_df(X_df)\n",
    "\n",
    "y = np.array(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Select which features you want to use !!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave out json name\n",
    "X = X_df.values[:, 1:]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data splitting, create training and test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data splitting functions\n",
    "from sklearn.model_selection import StratifiedKFold, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[ 3  4  7  8  9 10 11 14 15 16 17 18 19 20 21 22 23 24]\n",
      "  Test:  index=[ 0  1  2  5  6 12 13]\n",
      "Fold 1:\n",
      "  Train: index=[ 0  1  2  5  6  8 11 12 13 14 15 16 17 18 20 21 22 23 24]\n",
      "  Test:  index=[ 3  4  7  9 10 19]\n",
      "Fold 2:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  9 10 12 13 16 18 19 21 22 23 24]\n",
      "  Test:  index=[ 8 11 14 15 17 20]\n",
      "Fold 3:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 19 20]\n",
      "  Test:  index=[16 18 21 22 23 24]\n"
     ]
    }
   ],
   "source": [
    "# kf = KFold(n_splits=4, )\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4)\n",
    "\n",
    "# for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "#     print(f\"Fold {i}:\")\n",
    "#     print(f\"  Train: index={train_index}\")\n",
    "#     print(f\"  Test:  index={test_index}\")\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import clsasifiers\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# try multiclass with Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285714\n",
      "[False False False  True  True  True  True]\n",
      "0.5\n",
      "[False False False  True  True  True]\n",
      "0.6666666666666666\n",
      "[False  True False  True  True  True]\n",
      "0.6666666666666666\n",
      "[False  True  True False  True  True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habetsj\\Anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\habetsj\\Anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\habetsj\\Anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\habetsj\\Anaconda3\\envs\\ultraleap\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=4)\n",
    "\n",
    "# go from multiclass to binary\n",
    "# y_binary = y > 1\n",
    "\n",
    "# y = y_binary\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    \n",
    "    # loops over all folds\n",
    "\n",
    "    # get training and testing split for current fold\n",
    "    train_X, test_X = X[train_index], X[test_index]\n",
    "    train_y, test_y = y[train_index], y[test_index]\n",
    "    \n",
    "    # train classifier with train X and y\n",
    "    clf.fit(train_X, train_y)\n",
    "\n",
    "    y_pred = clf.predict(test_X)\n",
    "    y_true = test_y\n",
    "\n",
    "    print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "    # print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ultraleap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2b0f49e3f9f86e05f3035101dad0b7b3d97321cf2c3e74a112da03721bd9215"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
