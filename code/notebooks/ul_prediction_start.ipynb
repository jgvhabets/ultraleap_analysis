{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can be used to load raw ultraleap data, save cleaned dataframes for each block, and generate dataframes of distances for further feature extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import public packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from itertools import compress\n",
    "\n",
    "\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "import math\n",
    "import statistics as stat\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_path_in_notebook():\n",
    "    \"\"\"\n",
    "    Finds path of repo from Notebook.\n",
    "    Start running this once to correctly find\n",
    "    other modules/functions\n",
    "    \"\"\"\n",
    "    path = os.getcwd()\n",
    "    repo_name = 'ultraleap_analysis'\n",
    "\n",
    "    while path[-len(repo_name):] != 'ultraleap_analysis':\n",
    "\n",
    "        path = os.path.dirname(path)\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = get_repo_path_in_notebook()\n",
    "code_path = os.path.join(repo_path, 'code')\n",
    "os.chdir(code_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import own functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_data.import_and_convert_data as import_dat\n",
    "import import_data.find_paths as find_paths\n",
    "import import_data.preprocessing_meta_info as meta_info\n",
    "import sig_processing.segment_tasks as seg_tasks\n",
    "import movement_calc.helpfunctions as hp\n",
    "import feature_extraction.get_features as get_feat\n",
    "import feature_extraction.get_files as get_files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading Features (X) and scores (y)\n",
    "Load features from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df_path = os.path.join(repo_path, 'data', 'features', 'dataframes', 'patientdata')\n",
    "\n",
    "X_df = pd.read_csv(os.path.join(feat_df_path, 'ft_block_features.csv'), index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Load scores / labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_for_feat_df(ft_df):\n",
    "\n",
    "    y = []  # list to store labels\n",
    "\n",
    "    ids = X_df['filename']\n",
    "    if ids[0].startswith('feat'): ids = [x[5:-5] for x in ids]\n",
    "    else: ids = [x[:-5] for x in ids]\n",
    "\n",
    "    ids = [x.split('_') for x in ids]\n",
    "\n",
    "    for id_list in ids:\n",
    "        block, sub, cond, cam, task, side = id_list\n",
    "        value = get_scores(sub, cond, cam, task, side, block)\n",
    "        y.append(value)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(sub, cond, cam, task, side, block):\n",
    "\n",
    "    read_scores = pd.read_excel(os.path.join(\n",
    "        find_paths.find_onedrive_path('patientdata'),\n",
    "        f'scores_JB_JH_JR.xlsx'),\n",
    "        usecols='A:I'\n",
    "        )\n",
    "\n",
    "    read_scores.set_index('sub_cond_cam', inplace = True)\n",
    "\n",
    "    if side == 'left': side='lh'\n",
    "    elif side == 'right': side='rh'\n",
    "\n",
    "    # read scores for all blocks of a subject in the same cond, cam per side\n",
    "    ext_scores = read_scores.loc[f'{sub}_{cond}_{cam}'][f'{task}_{side}']\n",
    "\n",
    "    if type(ext_scores) != float:\n",
    "\n",
    "        if isinstance(ext_scores, int):\n",
    "            ls_int_sc = [ext_scores,]\n",
    "        else:\n",
    "            ls_int_sc = [int(s) for s in ext_scores if s in ['0', '1', '2', '3', '4']]\n",
    "\n",
    "\n",
    "        if block == 'b1':\n",
    "            score = ls_int_sc[0]\n",
    "        elif block == 'b2':\n",
    "            try:\n",
    "                score = ls_int_sc[1]\n",
    "            except IndexError:\n",
    "                score = ls_int_sc[0]\n",
    "\n",
    "        elif block == 'b3':\n",
    "            score = ls_int_sc[2]\n",
    "        else:\n",
    "            print(f'no scores for block {block} or block does not exist')\n",
    "            score = np.nan\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 13\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X16sdW50aXRsZWQ%3D?line=0'>1</a>\u001b[0m y \u001b[39m=\u001b[39m get_labels_for_feat_df(X_df)\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X16sdW50aXRsZWQ%3D?line=2'>3</a>\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_df' is not defined"
     ]
    }
   ],
   "source": [
    "y = get_labels_for_feat_df(X_df)\n",
    "\n",
    "y = np.array(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Select which features you want to use !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 15\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X21sdW50aXRsZWQ%3D?line=0'>1</a>\u001b[0m \u001b[39m# leave out json name\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X21sdW50aXRsZWQ%3D?line=1'>2</a>\u001b[0m X \u001b[39m=\u001b[39m X_df\u001b[39m.\u001b[39mvalues[:, \u001b[39m1\u001b[39m:]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_df' is not defined"
     ]
    }
   ],
   "source": [
    "# leave out json name\n",
    "X = X_df.values[:, 1:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data splitting, create training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data splitting functions\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "# kf = KFold(n_splits=4, )\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4)\n",
    "\n",
    "# for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "#     print(f\"Fold {i}:\")\n",
    "#     print(f\"  Train: index={train_index}\")\n",
    "#     print(f\"  Test:  index={test_index}\")\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import clsasifiers\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# try multiclass with Random Forest\n",
    "# import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = LinearSVC()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=4)\n",
    "\n",
    "# go from multiclass to binary\n",
    "# y_binary = y > 1\n",
    "\n",
    "# y = y_binary\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    \n",
    "    # loops over all folds\n",
    "\n",
    "    # get training and testing split for current fold\n",
    "    train_X, test_X = X[train_index], X[test_index]\n",
    "    train_y, test_y = y[train_index], y[test_index]\n",
    "    \n",
    "    # train classifier with train X and y\n",
    "    clf.fit(train_X, train_y)\n",
    "\n",
    "    y_pred = clf.predict(test_X)\n",
    "    y_true = test_y\n",
    "\n",
    "    print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "    # print(y_true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultraleap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
